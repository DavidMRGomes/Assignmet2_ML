{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code **should not** be run, if so, it will overwrite the previous existing data, contradicting what it was originally used for (having the same train/validation/test data to produce consistent results). The purpose of this code is to show how the data split was done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import splitfolders\n",
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.utils import save_image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the paths\n",
    "dataset_path = 'flowers'\n",
    "train_val_test_path = 'tvt_flowers'\n",
    "train_path = os.path.join(train_val_test_path,\"train\")\n",
    "test_path = os.path.join(train_val_test_path,\"test\")\n",
    "val_path = os.path.join(train_val_test_path,\"val\")\n",
    "#Path to data augmented with the CIFAR10,IMAGENET, and SVHN pre built transformations from PyTorch\n",
    "train_aug_path = os.path.join(train_val_test_path,\"train_aug\")\n",
    "#Path to data augmented with the IMAGENET pre-build transformation form Pytorch\n",
    "train_less_aug_path = os.path.join(train_val_test_path,\"train_less_aug\")\n",
    "#Path to data augmented with three different transforms - rotations, affine, flips, collor jitter, erasing\n",
    "train_simple_aug_path = os.path.join(train_val_test_path,\"train_simple_aug\")\n",
    "#Path to normalized training data\n",
    "train_norm_path = os.path.join(train_val_test_path,\"train_normalized\")\n",
    "#Path to data augmented with a single transformation containing rotations, affine, flips\n",
    "train_one_aug_path = os.path.join(train_val_test_path,\"train_one_aug\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 4317 files [00:09, 449.54 files/s]\n"
     ]
    }
   ],
   "source": [
    "#Split into three foldes, train, val, and test\n",
    "splitfolders.ratio(dataset_path, output=train_val_test_path, seed=1337, ratio=(.72, 0.08,0.2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Means and stds for normalization\n",
    "channel_means = torch.Tensor([0.4590, 0.4201, 0.3005])\n",
    "channel_std = torch.Tensor([0.2940, 0.2635, 0.2863])\n",
    "\n",
    "#Define the three transformations\n",
    "transformations = {}\n",
    "\n",
    "transformations['original'] = transforms.Compose([\n",
    "                                                transforms.Resize((220, 220)),\n",
    "                                                transforms.ToTensor(), \n",
    "                                                transforms.Normalize((channel_means[0].item(), channel_means[1].item(), channel_means[2].item()), \n",
    "                                                                    (channel_std[0].item(), channel_std[1].item(), channel_std[2].item()))])\n",
    "\n",
    "dataset = {}\n",
    "dataset['original'] = ImageFolder(train_path, transform=transformations['original'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pytorch Built-in Transformations\n",
    "transformations['CIFAR10'] = transforms.Compose([\n",
    "                                                transforms.AutoAugment(transforms.AutoAugmentPolicy.CIFAR10),\n",
    "                                                transforms.Resize((220, 220)),\n",
    "                                                transforms.ToTensor(), \n",
    "                                                transforms.Normalize((channel_means[0].item(), channel_means[1].item(), channel_means[2].item()), \n",
    "                                                                    (channel_std[0].item(), channel_std[1].item(), channel_std[2].item()))])\n",
    "\n",
    "\n",
    "transformations['IMAGENET'] = transforms.Compose([\n",
    "                                                transforms.AutoAugment(transforms.AutoAugmentPolicy.IMAGENET),\n",
    "                                                transforms.Resize((220, 220)),\n",
    "                                                transforms.ToTensor(), \n",
    "                                                transforms.Normalize((channel_means[0].item(), channel_means[1].item(), channel_means[2].item()), \n",
    "                                                                    (channel_std[0].item(), channel_std[1].item(), channel_std[2].item()))])\n",
    "\n",
    "transformations['SVHN'] = transforms.Compose([\n",
    "                                                transforms.AutoAugment(transforms.AutoAugmentPolicy.SVHN),\n",
    "                                                transforms.Resize((220, 220)),\n",
    "                                                transforms.ToTensor(), \n",
    "                                                transforms.Normalize((channel_means[0].item(), channel_means[1].item(), channel_means[2].item()), \n",
    "                                                                    (channel_std[0].item(), channel_std[1].item(), channel_std[2].item()))])\n",
    "\n",
    "#Apply the three diferent trasnformations to the dataset and store them\n",
    "\n",
    "dataset['CIFAR10'] = ImageFolder(train_path, transform=transformations['CIFAR10'])\n",
    "dataset['IMAGENET'] = ImageFolder(train_path, transform=transformations['IMAGENET'])\n",
    "dataset['SVHN'] = ImageFolder(train_path, transform=transformations['SVHN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"Simple\" Transformation\n",
    "\n",
    "transformations['Flip_Rot_Aff'] = transforms.Compose([\n",
    "                                 transforms.Resize((220, 220)),\n",
    "                                 transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                 transforms.RandomRotation(15),\n",
    "                                 transforms.RandomAffine(translate=(0.08,0.1), degrees=15),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((channel_means[0].item(), channel_means[1].item(), channel_means[2].item()), \n",
    "                                                                    (channel_std[0].item(), channel_std[1].item(), channel_std[2].item()))])\n",
    "\n",
    "transformations['Random_Erasing'] = transforms.Compose([\n",
    "                                 transforms.Resize((220, 220)),\n",
    "                                 transforms.RandomHorizontalFlip(),\n",
    "                                 transforms.RandomRotation(10),\n",
    "                                 transforms.RandomAffine(translate=(0.05,0.05), degrees=0),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.RandomErasing(inplace=True, scale=(0.01, 0.23)),\n",
    "                                 transforms.Normalize((channel_means[0].item(), channel_means[1].item(), channel_means[2].item()), \n",
    "                                                                    (channel_std[0].item(), channel_std[1].item(), channel_std[2].item()))])\n",
    "\n",
    "transformations['Color_Jitter'] = transforms.Compose([\n",
    "                                 transforms.Resize((220, 220)),\n",
    "                                 transforms.RandomHorizontalFlip(),\n",
    "                                 transforms.RandomRotation(5),\n",
    "                                 transforms.RandomAffine(translate=(0.05,0.05), degrees=0),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.ColorJitter(brightness=0.2,contrast=0.2, saturation=0.2),\n",
    "                                 transforms.Normalize((channel_means[0].item(), channel_means[1].item(), channel_means[2].item()), \n",
    "                                                                    (channel_std[0].item(), channel_std[1].item(), channel_std[2].item()))])\n",
    "                                                \n",
    "dataset['Flip_Rot_Aff'] = ImageFolder(train_path, transform=transformations['Flip_Rot_Aff'])\n",
    "dataset['Random_Erasing'] = ImageFolder(train_path, transform=transformations['Random_Erasing'])\n",
    "dataset['Color_Jitter'] = ImageFolder(train_path, transform=transformations['Color_Jitter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One Augmentation Transformation\n",
    "\n",
    "transformations['Flip_Rot_Aff_Modified'] = transforms.Compose([\n",
    "                                 transforms.Resize((220, 220)),\n",
    "                                 transforms.RandomHorizontalFlip(p=0.3),\n",
    "                                 transforms.RandomRotation(10),\n",
    "                                 transforms.RandomAffine(translate=(0.08,0.1), degrees=15),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((channel_means[0].item(), channel_means[1].item(), channel_means[2].item()), \n",
    "                                                                    (channel_std[0].item(), channel_std[1].item(), channel_std[2].item()))])\n",
    "\n",
    "dataset['One_Aug'] = ImageFolder(train_path, transform=transformations['Flip_Rot_Aff_Modified'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate directories to store the augmented images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory daisy already exists\n",
      "Directory dandelion already exists\n",
      "Directory rose already exists\n",
      "Directory rose already exists\n",
      "Directory rose already exists\n",
      "Directory daisy already exists\n",
      "Directory dandelion already exists\n",
      "Directory rose already exists\n",
      "Directory rose already exists\n",
      "Directory rose already exists\n",
      "Directory daisy already exists\n",
      "Directory dandelion already exists\n",
      "Directory rose already exists\n",
      "Directory rose already exists\n",
      "Directory rose already exists\n",
      "Directory daisy already exists\n",
      "Directory dandelion already exists\n",
      "Directory rose already exists\n",
      "Directory rose already exists\n",
      "Directory rose already exists\n"
     ]
    }
   ],
   "source": [
    "aug_paths = [train_aug_path, train_less_aug_path, train_simple_aug_path, train_norm_path, train_one_aug_path]\n",
    "\n",
    "for aug_path in aug_paths:\n",
    "    try:\n",
    "        os.makedirs(os.path.join(aug_path,\"daisy\"))\n",
    "    except:\n",
    "        print(\"Directory daisy already exists\")\n",
    "\n",
    "    try:\n",
    "        os.makedirs(os.path.join(aug_path,\"dandelion\"))\n",
    "    except:\n",
    "        print(\"Directory dandelion already exists\")\n",
    "\n",
    "    try:\n",
    "        os.makedirs(os.path.join(aug_path,\"rose\"))\n",
    "    except:\n",
    "        print(\"Directory rose already exists\")\n",
    "\n",
    "    try:\n",
    "        os.makedirs(os.path.join(aug_path,\"sunflower\"))\n",
    "    except:\n",
    "        print(\"Directory rose already exists\")\n",
    "\n",
    "    try:\n",
    "        os.makedirs(os.path.join(aug_path,\"tulip\"))\n",
    "    except:\n",
    "        print(\"Directory rose already exists\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below saves the augmented images from the 'original', 'CIFAR10', 'IMAGENET',  and 'SVHN' datasets storing in train_aug.  It also stores the images from 'original' and 'IMAGENET' datasets in another folder, train_less_aug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3106it [00:29, 104.62it/s]\n",
      "3106it [00:36, 85.75it/s] \n",
      "3106it [00:36, 84.77it/s] \n",
      "3106it [00:32, 97.03it/s] \n"
     ]
    }
   ],
   "source": [
    "keys = [\"original\", \"CIFAR10\", \"IMAGENET\", \"SVHN\"]\n",
    "\n",
    "for i, key in enumerate(keys):\n",
    "    for idx, data_label in tqdm(enumerate(dataset[key])):\n",
    "        data, label = data_label\n",
    "        if label == 0:\n",
    "            path_to_save = os.path.join(train_aug_path,\"daisy\")\n",
    "            if i == 0 or i == 2:\n",
    "                save_image(data,os.path.join(train_less_aug_path,\"daisy\",\"image{}_{}.jpg\".format(i,idx)))\n",
    "        elif label == 1:\n",
    "            path_to_save = os.path.join(train_aug_path,\"dandelion\")\n",
    "            if i == 0 or i == 2:\n",
    "                save_image(data,os.path.join(train_less_aug_path,\"dandellion\",\"image{}_{}.jpg\".format(i,idx)))\n",
    "        elif label == 2:\n",
    "            path_to_save = os.path.join(train_aug_path,\"rose\")\n",
    "            if i == 0 or i == 2:\n",
    "                save_image(data,os.path.join(train_less_aug_path,\"rose\",\"image{}_{}.jpg\".format(i,idx)))\n",
    "        elif label == 3:\n",
    "            path_to_save = os.path.join(train_aug_path,\"sunflower\")\n",
    "            if i == 0 or i == 2:\n",
    "                save_image(data,os.path.join(train_less_aug_path,\"sunflower\",\"image{}_{}.jpg\".format(i,idx)))\n",
    "        elif label == 4:\n",
    "            path_to_save = os.path.join(train_aug_path,\"tulip\")\n",
    "            if i == 0 or i == 2:\n",
    "                save_image(data,os.path.join(train_less_aug_path,\"tulip\",\"image{}_{}.jpg\".format(i,idx)))\n",
    "    \n",
    "        save_image(data,os.path.join(path_to_save,\"image{}_{}.jpg\".format(i,idx)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stores the \"original\", \"Flip_Rot_Aff\", \"Random_Erasing\", and \"Color_Jitter\" datasets in train_simple_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3106it [00:31, 100.08it/s]\n",
      "3106it [00:34, 89.78it/s] \n",
      "3106it [00:35, 87.78it/s] \n",
      "3106it [00:42, 73.35it/s]\n"
     ]
    }
   ],
   "source": [
    "keys = [\"original\", \"Flip_Rot_Aff\", \"Random_Erasing\", \"Color_Jitter\"]\n",
    "\n",
    "for i, key in enumerate(keys):\n",
    "    for idx, data_label in tqdm(enumerate(dataset[key])):\n",
    "        data, label = data_label\n",
    "        if label == 0:\n",
    "            path_to_save = os.path.join(train_simple_aug_path,\"daisy\")\n",
    "        elif label == 1:\n",
    "            path_to_save = os.path.join(train_simple_aug_path,\"dandelion\")\n",
    "        elif label == 2:\n",
    "            path_to_save = os.path.join(train_simple_aug_path,\"rose\")\n",
    "        elif label == 3:\n",
    "            path_to_save = os.path.join(train_simple_aug_path,\"sunflower\")\n",
    "        elif label == 4:\n",
    "            path_to_save = os.path.join(train_simple_aug_path,\"tulip\")\n",
    "    \n",
    "        save_image(data,os.path.join(path_to_save,\"image{}_{}.jpg\".format(i,idx)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stores the training data normalized in the folder train_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, data_label in tqdm(enumerate(dataset['original'])):\n",
    "    data, label = data_label\n",
    "    if label == 0:\n",
    "        path_to_save = os.path.join(train_norm_path,\"daisy\")\n",
    "    elif label == 1:\n",
    "        path_to_save = os.path.join(train_norm_path,\"dandelion\")\n",
    "    elif label == 2:\n",
    "        path_to_save = os.path.join(train_norm_path,\"rose\")\n",
    "    elif label == 3:\n",
    "        path_to_save = os.path.join(train_norm_path,\"sunflower\")\n",
    "    elif label == 4:\n",
    "        path_to_save = os.path.join(train_norm_path,\"tulip\")\n",
    "\n",
    "    save_image(data,os.path.join(path_to_save,\"image{}.jpg\".format(idx)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stores the 'original' and 'One_Aug' datasets in train_one_aug folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3106it [00:39, 78.48it/s]\n",
      "3106it [00:31, 98.60it/s] \n"
     ]
    }
   ],
   "source": [
    "keys = [\"original\", \"One_Aug\"]\n",
    "\n",
    "for i, key in enumerate(keys):\n",
    "    for idx, data_label in tqdm(enumerate(dataset[key])):\n",
    "        data, label = data_label\n",
    "        if label == 0:\n",
    "                save_image(data,os.path.join(train_one_aug_path,\"daisy\",\"image{}_{}.jpg\".format(i,idx)))\n",
    "        elif label == 1:\n",
    "                save_image(data,os.path.join(train_one_aug_path,\"dandelion\",\"image{}_{}.jpg\".format(i,idx)))\n",
    "        elif label == 2:\n",
    "                save_image(data,os.path.join(train_one_aug_path,\"rose\",\"image{}_{}.jpg\".format(i,idx)))\n",
    "        elif label == 3:\n",
    "                save_image(data,os.path.join(train_one_aug_path,\"sunflower\",\"image{}_{}.jpg\".format(i,idx)))\n",
    "        elif label == 4:\n",
    "                save_image(data,os.path.join(train_one_aug_path,\"tulip\",\"image{}_{}.jpg\".format(i,idx)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "37b255bb5dc0d995b91bd1b934b878e610a26475f52eafaf29fdb395fb105534"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
